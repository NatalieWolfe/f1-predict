task = train
boosting_type = gbdt
objective = lambdarank
metric = ndcg

header = true

label_column = 0
group_column = 1
categorical_features = 2,3,4,5
# label_column = name:relevance_label
# group_column = name:race_id
# categorical_features = name:season,circuit_id,team_id,driver_id
# features = name:starting_position,q1_time_msec,q2_time_msec,q3_time_msec,driver_best_q_time_msec,gap_to_best_q_time_msec

train = "bazel-bin/training/training.csv"
valid = "bazel-bin/training/tests.csv"

# Evaluate 1st place, podium, and top-5 accuracy
eval_at = 1,3,5
# Alternatives to try: 31 (default), 20, 40, 50
num_leaves = 31
# Consider shrinking to increase accuracy (also increase num_iterations).
learning_rate = 0.05
num_iterations = 500
early_stopping_round = 100

output_model = "f1_lambdarank_model.txt"
